{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT for Question Answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squadv2 = load_dataset('squad_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(squadv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our sequences will look like\n",
    "\n",
    "```\n",
    "[CLS] ...question tokens... [SEP] ...context tokens... [SEP]\n",
    "```\n",
    "\n",
    "In cases where the context is too long, we'll split into multiple sequences, like\n",
    "\n",
    "```\n",
    "[CLS] ...question tokens... [SEP] ...some context tokens... [SEP]\n",
    "[CLS] ...question tokens... [SEP] ...overlap from prev sequence... ...more context tokens... [SEP]\n",
    "...\n",
    "```\n",
    "\n",
    "Bassed on the question tokens, the model needs to get a contiguous subset of the context tokens as the answer. Our dataset contains the start position of the answer in the original context string.\n",
    "\n",
    "The HuggingFace tokenizer is able to map each item in the tokenized sequence to the start and end indices in the original context string.\n",
    "\n",
    "We need to find which indices in the tokenized sequence map to the start and end of the answer so that our model knows how to predict the contiguous answer section.\n",
    "\n",
    "If there is no answer available in a sequence, we will set the answer start and end to the `[CLS]` token.\n",
    "\n",
    "Additionally, for context split accross multiple tokenized sequences, for sequences without the answer (or with only a part of the answer), we will treat it the same as 'no answer' sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_answer(offset, ans_start, ans_end, sequence_ids):\n",
    "\n",
    "    # get start and end indices in tokenized sequence\n",
    "    idx = 0\n",
    "    while sequence_ids[idx] != 1: idx += 1\n",
    "    context_start = idx\n",
    "    while sequence_ids[idx] == 1: idx += 1\n",
    "    context_end = idx - 1\n",
    "\n",
    "    # start with [CLS]\n",
    "    start, end = 0, 0\n",
    "\n",
    "    # if answer is not fully in this tokenized sequence, map to [CLS]\n",
    "    if offset[context_end][0] > ans_end or offset[context_end][1] < ans_start:\n",
    "        return start, end\n",
    "    \n",
    "    idx = context_start\n",
    "    while idx <= context_end and offset[idx][0] <= ans_start: idx += 1\n",
    "    start = idx - 1\n",
    "\n",
    "    idx = context_end\n",
    "    while idx >= context_start and offset[idx][1] >= ans_end: idx -= 1\n",
    "    end = idx + 1\n",
    "\n",
    "    return start, end\n",
    "\n",
    "def get_answer_mapped_data(batch):\n",
    "    questions = batch['question']\n",
    "    contexts = batch['context']\n",
    "    answers = batch['answers']\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        # add data for tokenizing and padding\n",
    "        questions, contexts,        # data to tokenize\n",
    "        max_length=400,             # max_length per sequence\n",
    "        padding='max_length',       # pad til max_length\n",
    "\n",
    "        # handling truncation\n",
    "        truncation='only_second',   # only truncate context\n",
    "        stride=128,                 # overlap size\n",
    "        return_overflowing_tokens=True, # tokenizer automatically \n",
    "                                        # makes extra sequences\n",
    "\n",
    "        # get mappings to original sentence\n",
    "        return_offsets_mapping=True,# used to map answer to sequence\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop('offset_mapping')\n",
    "    sample_map = inputs.pop('overflow_to_sample_mapping')\n",
    "    starts = []\n",
    "    ends = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "\n",
    "        map_i = sample_map[i]\n",
    "\n",
    "        answer = answers[map_i]\n",
    "        text = answer['text']\n",
    "        \n",
    "        # SQuAD v2 has some adversarial examples with 'unanswerable' questions\n",
    "        # in this case, map to [CLS]\n",
    "        if len(text) < 1:\n",
    "            starts.append(0)\n",
    "            ends.append(0)\n",
    "            continue\n",
    "\n",
    "        ans_start = answer['answer_start'][0]\n",
    "        ans_end = ans_start + len(text[0])\n",
    "        sequence_ids = inputs.sequence_ids(map_i)\n",
    "\n",
    "        start, end = map_answer(offset, ans_start, ans_end, sequence_ids)\n",
    "\n",
    "        starts.append(start)\n",
    "        ends.append(end)\n",
    "\n",
    "    inputs['start_positions'] = starts\n",
    "    inputs['end_positions'] = ends\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_squadv2 = squadv2.map(get_answer_mapped_data,\n",
    "                                batched=True,\n",
    "                                remove_columns=squadv2['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_squadv2['train'][0].keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up HuggingFace Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from transformers import DefaultDataCollator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use DistilBERT for lower memory usage and thus faster training (from larger batch sizes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbert_qa = AutoModelForQuestionAnswering.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "LR = 2e-5\n",
    "EPOCHS = 3\n",
    "WEIGHT_DECAY = 0.01\n",
    "CHKPT_DIR = 'checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    # save model\n",
    "    output_dir=CHKPT_DIR,\n",
    "\n",
    "    # epochs\n",
    "    evaluation_strategy='epoch',\n",
    "    num_train_epochs=EPOCHS,\n",
    "\n",
    "    # batch sizes\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    \n",
    "    # hyperparams\n",
    "    learning_rate=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "\n",
    "    # log to wandb\n",
    "    report_to='wandb',\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=dbert_qa,\n",
    "    args=train_args,\n",
    "    train_dataset=tokenized_squadv2['train'],\n",
    "    eval_dataset=tokenized_squadv2['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# use to log in to wandb if needed\n",
    "# API_KEY = # wandb api key\n",
    "# wandb.login(key=API_KEY)\n",
    "\n",
    "wandb.init(\n",
    "    project='SQuAD2.0 with Fine-Tuned DistilBERT',\n",
    "    notes='Solving Standford\\'s SQuAD 2.0 Q&A dataset with DistilBERT transfer learning.',\n",
    ")\n",
    "\n",
    "wandb.config = {\n",
    "    'epochs': EPOCHS, \n",
    "    'learning_rate': LR, \n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'weight_decay': WEIGHT_DECAY,\n",
    "}\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert-transfer-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
